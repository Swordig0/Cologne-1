{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = 1\n",
    "fps = 60\n",
    "\n",
    "model_version = \"my_model_13.0.keras\"\n",
    "Im_Width = 128\n",
    "Im_Height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(frame, x, y, w, h):\n",
    "    return frame[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_brightness(frame):\n",
    "    cropped_frame = crop_image(frame, 120, 0, 400, 250)\n",
    "    gray = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    brightness = np.mean(gray)  # Compute the mean intensity\n",
    "    return brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_frame(frame_buffer):\n",
    "    best_frame = None\n",
    "    best_score = -1 \n",
    "\n",
    "    for frame in frame_buffer:\n",
    "        score = measure_brightness(frame)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_frame = frame\n",
    "\n",
    "    return best_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, target_size):\n",
    "    \n",
    "    # Resize the frame to the target size\n",
    "    resized_frame = cv2.resize(frame, target_size)\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "\n",
    "    # Convert to NumPy array and add batch dimension\n",
    "    frame_array = img_to_array(normalized_frame)\n",
    "    frame_array = np.expand_dims(frame_array, axis=0)  # Shape: (1, height, width, channels)\n",
    "\n",
    "    return frame_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame(frame, model, target_size):\n",
    "\n",
    "    # Preprocess the frame\n",
    "    frame_array = process_frame(frame, target_size)\n",
    "\n",
    "    # Make a prediction\n",
    "    predictions = model.predict(frame_array)  # Outputs probabilities for each class\n",
    "    predicted_class = np.argmax(predictions[0])  # Get the index of the class with the highest probability\n",
    "    confidence = predictions[0][predicted_class]  # Confidence score for the predicted class\n",
    "\n",
    "    # Map class indices to labels\n",
    "    class_labels = {0: \"Defective\", 2: \"Non-Defective\", 1: \"No Bottle\"} \n",
    "    predicted_label = class_labels[predicted_class]\n",
    "\n",
    "    return predicted_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(cam, fps, model_path, target_size=(Im_Width, Im_Height)):\n",
    "    cap = cv2.VideoCapture(cam)  # Open webcam\n",
    "    # Set desired frame rate\n",
    "    desired_fps = fps \n",
    "    cap.set(cv2.CAP_PROP_FPS, desired_fps)\n",
    "\n",
    "    frame_buffer = []\n",
    "    max_frames = 30  # Number of frames to evaluate\n",
    "\n",
    "    # Load the model\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        frame = cap.read()\n",
    "\n",
    "        frame_buffer.append(frame)\n",
    "\n",
    "        # Process the buffer when it's full\n",
    "        if len(frame_buffer) == max_frames:\n",
    "            best_frame = select_best_frame(frame_buffer)\n",
    "            frame_buffer = []  # Clear the buffer\n",
    "\n",
    "            # Process and predict\n",
    "            feedback, confidence = predict_frame(best_frame, model, target_size)\n",
    "            print(f\"Prediction: {feedback} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "            cv2.putText(best_frame, f\"Prediction: {feedback}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(best_frame, f\"Confidence: {confidence:.2f}\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Display the best frame\n",
    "            cv2.imshow(\"Best Frame\", best_frame)\n",
    "\n",
    "        # Exit on 'ESC' key\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m model_version  \u001b[38;5;66;03m# Path to your saved model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIm_Width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIm_Height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mcapture\u001b[1;34m(cam, fps, model_path, target_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Process the buffer when it's full\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frame_buffer) \u001b[38;5;241m==\u001b[39m max_frames:\n\u001b[1;32m---> 23\u001b[0m     best_frame \u001b[38;5;241m=\u001b[39m \u001b[43mselect_best_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     frame_buffer \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Clear the buffer\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Process and predict\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mselect_best_frame\u001b[1;34m(frame_buffer)\u001b[0m\n\u001b[0;32m      3\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frame_buffer:\n\u001b[1;32m----> 6\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_brightness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[0;32m      8\u001b[0m         best_score \u001b[38;5;241m=\u001b[39m score\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mmeasure_brightness\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_brightness\u001b[39m(frame):\n\u001b[1;32m----> 2\u001b[0m     cropped_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcrop_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cropped_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     brightness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(gray)  \u001b[38;5;66;03m# Compute the mean intensity\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mcrop_image\u001b[1;34m(frame, x, y, w, h)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop_image\u001b[39m(frame, x, y, w, h):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_path = model_version  # Path to your saved model\n",
    "    capture(cam, fps, model_path, target_size=(Im_Width, Im_Height))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
